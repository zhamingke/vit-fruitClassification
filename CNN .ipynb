{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48568b8e-5c5d-40e6-ab08-8423a17e8c95",
   "metadata": {},
   "source": [
    "Using CNN to Achieve Fruit Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e83c15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已解压到: fruit\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "zip_file_path = 'fruits-360.zip'\n",
    "extract_folder = 'fruit'\n",
    "\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(f\" {extract_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1164171d-d44e-4551-9e8c-4babbb3d295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      " 数据集中包含 141 种水果类别\n",
      "开始训练 ResNet-34 ...\n",
      "Epoch [1/20] - Loss: 4.6127, Train Acc: 0.0533, Val Acc: 0.1295\n",
      "Model Saved!\n",
      "Epoch [2/20] - Loss: 3.5520, Train Acc: 0.1479, Val Acc: 0.2836\n",
      "Model Saved!\n",
      "Epoch [3/20] - Loss: 3.2178, Train Acc: 0.1870, Val Acc: 0.3289\n",
      "Model Saved!\n",
      "Epoch [4/20] - Loss: 3.0317, Train Acc: 0.2205, Val Acc: 0.3271\n",
      "Epoch [5/20] - Loss: 2.9530, Train Acc: 0.2278, Val Acc: 0.3008\n",
      "Epoch [6/20] - Loss: 2.8597, Train Acc: 0.2454, Val Acc: 0.2499\n",
      "Epoch [7/20] - Loss: 2.7990, Train Acc: 0.2602, Val Acc: 0.3531\n",
      "Model Saved!\n",
      "Epoch [8/20] - Loss: 2.6779, Train Acc: 0.2735, Val Acc: 0.4014\n",
      "Model Saved!\n",
      "Epoch [9/20] - Loss: 2.6844, Train Acc: 0.2860, Val Acc: 0.4127\n",
      "Model Saved!\n",
      "Epoch [10/20] - Loss: 2.7507, Train Acc: 0.2724, Val Acc: 0.3390\n",
      "Epoch [11/20] - Loss: 2.3971, Train Acc: 0.3514, Val Acc: 0.7128\n",
      "Model Saved!\n",
      "Epoch [12/20] - Loss: 2.1308, Train Acc: 0.4512, Val Acc: 0.7821\n",
      "Model Saved!\n",
      "Epoch [13/20] - Loss: 2.0727, Train Acc: 0.4605, Val Acc: 0.7772\n",
      "Epoch [14/20] - Loss: 2.0404, Train Acc: 0.4588, Val Acc: 0.7968\n",
      "Model Saved!\n",
      "Epoch [15/20] - Loss: 1.9646, Train Acc: 0.4773, Val Acc: 0.7948\n",
      "Epoch [16/20] - Loss: 1.9679, Train Acc: 0.4764, Val Acc: 0.8280\n",
      "Model Saved!\n",
      "Epoch [17/20] - Loss: 1.9280, Train Acc: 0.4877, Val Acc: 0.8167\n",
      "Epoch [18/20] - Loss: 1.8745, Train Acc: 0.5085, Val Acc: 0.8177\n",
      "Epoch [19/20] - Loss: 1.7959, Train Acc: 0.5265, Val Acc: 0.8187\n",
      "Epoch [20/20] - Loss: 1.8192, Train Acc: 0.5132, Val Acc: 0.8326\n",
      "Model Saved!\n",
      "训练完成！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet34\n",
    "from timm.data import RandomResizedCropAndInterpolation\n",
    "from torchvision.transforms import RandomErasing,RandAugment\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"log34-40.txt\",  \n",
    "    filemode=\"w\", \n",
    "    level=logging.INFO, \n",
    "    format=\"%(asctime)s - %(message)s\",  \n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "\n",
    "def log_print(message):\n",
    "    print(message) \n",
    "    logging.info(message) \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "log_print(f\"Using device: {device}\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation='bicubic'),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    RandAugment(num_ops=2,magnitude=9),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    RandomErasing(p=0.5) \n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC, antialias=True),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"fruits-360/5%/train\", transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=\"fruits-360/5%/val\", transform=val_transform)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "log_print(f\" include {num_classes} category\")\n",
    "\n",
    "model = resnet34(pretrained=False)\n",
    "model.fc = nn.Linear(512, num_classes)  \n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2.5e-4, weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        log_print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "                  f\"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"resnet18_fruits360.pth\")\n",
    "            log_print(\"Model Saved!\")\n",
    "\n",
    "log_print(\"train ResNet-34 ...\")\n",
    "train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20)\n",
    "log_print(\"finish！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d234530-2915-4370-99cc-42e2ae6fdd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99504c6-967c-477f-8f6f-e5af18f598d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
